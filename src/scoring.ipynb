{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pose_dataset import PoseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 33 * 3\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2 # number of RNNs to stack\n",
    "NUM_CLASSES = 9 # number of categories\n",
    "\n",
    "LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_DIM = 1\n",
    "BATCH_DIM = 0\n",
    "COORD_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseScoringModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(PoseScoringModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        h0 = torch.zeros(self.num_layers, X.size(BATCH_DIM), self.hidden_size).to(device)\n",
    "        out, _ = self.gru(X, h0)\n",
    "        # out: batch x time x hidden\n",
    "        out = out[:, -1, :]\n",
    "        # out: batch x hidden\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoseScoringModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility (optional)\n",
    "# random.seed(42)\n",
    "\n",
    "# Set the training ratio (90% training, 10% testing)\n",
    "train_ratio = 0.9\n",
    "\n",
    "# Define target directories\n",
    "train_dir = \"../data/train\"\n",
    "test_dir = \"../data/test\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get a sorted list of all data files\n",
    "data_files = sorted(glob.glob(\"../data/data_*.mat\"))\n",
    "data_files = data_files[:19]\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Get the base filename without extension, e.g., \"data_000\"\n",
    "    base_name = os.path.splitext(os.path.basename(data_file))[0]\n",
    "    parts = base_name.split('_')\n",
    "    if len(parts) != 2:\n",
    "        print(f\"Skipping invalid file name: {data_file}\")\n",
    "        continue\n",
    "    number = parts[1]  # e.g., \"000\"\n",
    "    \n",
    "    # Construct the corresponding metric filename\n",
    "    metric_file = f\"../data/metric_{number}.mat\"\n",
    "    \n",
    "    # Check if the corresponding metric file exists\n",
    "    if not os.path.exists(metric_file):\n",
    "        print(f\"Warning: {metric_file} not found for {data_file}\")\n",
    "        continue\n",
    "\n",
    "    # Choose destination based on random split\n",
    "    destination = train_dir if random.random() < train_ratio else test_dir\n",
    "\n",
    "    # Move both files\n",
    "    shutil.move(data_file, os.path.join(destination, os.path.basename(data_file)))\n",
    "    shutil.move(metric_file, os.path.join(destination, os.path.basename(metric_file)))\n",
    "    \n",
    "    print(f\"Moved pair ({data_file}, {metric_file}) to {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PoseData(\"../data/train\")\n",
    "test_data = PoseData(\"../data/test\")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "# train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Fold [1/5], Epoch [1/100], Step [1/5], Loss: 0.6985\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [2/100], Step [1/5], Loss: 0.6856\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [3/100], Step [1/5], Loss: 0.6987\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [4/100], Step [1/5], Loss: 0.6885\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [5/100], Step [1/5], Loss: 0.7054\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [6/100], Step [1/5], Loss: 0.6857\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [7/100], Step [1/5], Loss: 0.6604\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [8/100], Step [1/5], Loss: 0.6168\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [9/100], Step [1/5], Loss: 0.6159\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [10/100], Step [1/5], Loss: 0.6827\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [11/100], Step [1/5], Loss: 0.6291\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [12/100], Step [1/5], Loss: 0.6119\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [13/100], Step [1/5], Loss: 0.6597\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [14/100], Step [1/5], Loss: 0.6541\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [15/100], Step [1/5], Loss: 0.6226\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [16/100], Step [1/5], Loss: 0.5851\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [17/100], Step [1/5], Loss: 0.5904\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [18/100], Step [1/5], Loss: 0.6346\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [19/100], Step [1/5], Loss: 0.5993\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [20/100], Step [1/5], Loss: 0.6206\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [21/100], Step [1/5], Loss: 0.5760\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [22/100], Step [1/5], Loss: 0.6378\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [23/100], Step [1/5], Loss: 0.5808\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [24/100], Step [1/5], Loss: 0.5989\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [25/100], Step [1/5], Loss: 0.5979\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [26/100], Step [1/5], Loss: 0.6208\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [27/100], Step [1/5], Loss: 0.5687\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [28/100], Step [1/5], Loss: 0.5663\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [29/100], Step [1/5], Loss: 0.5656\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [30/100], Step [1/5], Loss: 0.5982\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [31/100], Step [1/5], Loss: 0.5590\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [32/100], Step [1/5], Loss: 0.6239\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [33/100], Step [1/5], Loss: 0.5779\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [34/100], Step [1/5], Loss: 0.6050\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [35/100], Step [1/5], Loss: 0.6018\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [36/100], Step [1/5], Loss: 0.5907\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [37/100], Step [1/5], Loss: 0.5914\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [38/100], Step [1/5], Loss: 0.5720\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [39/100], Step [1/5], Loss: 0.5876\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [40/100], Step [1/5], Loss: 0.5692\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [41/100], Step [1/5], Loss: 0.5564\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [42/100], Step [1/5], Loss: 0.5825\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [43/100], Step [1/5], Loss: 0.5793\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [44/100], Step [1/5], Loss: 0.6047\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [45/100], Step [1/5], Loss: 0.5901\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [46/100], Step [1/5], Loss: 0.5916\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [47/100], Step [1/5], Loss: 0.5713\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [48/100], Step [1/5], Loss: 0.5753\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [49/100], Step [1/5], Loss: 0.5869\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [50/100], Step [1/5], Loss: 0.5756\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [51/100], Step [1/5], Loss: 0.6194\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [52/100], Step [1/5], Loss: 0.5568\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [53/100], Step [1/5], Loss: 0.5834\n",
      "TARGETS torch.Size([32, 9]), INPUTStorch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.5382\n",
      "Fold [1/5], Epoch [54/100], Step [1/5], Loss: 0.5350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m     31\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/programming/catapult/Catapult2025/src/pose_dataset.py:20\u001b[39m, in \u001b[36mPoseData.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     mat_data = \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     label_data = loadmat(\u001b[38;5;28mself\u001b[39m.labels[idx])\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Replace 'data' and 'label' with the actual variable names in your .mat files\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# For example, if your main variable in the input file is stored under the key \"data\"\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# and in the label file under \"label\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/scipy/io/matlab/_mio.py:235\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    234\u001b[39m     MR, _ = mat_reader_factory(f, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     matfile_dict = \u001b[43mMR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spmatrix:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse, coo_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/scipy/io/matlab/_mio5.py:339\u001b[39m, in \u001b[36mMatFile5Reader.get_variables\u001b[39m\u001b[34m(self, variable_names)\u001b[39m\n\u001b[32m    335\u001b[39m     warnings.warn(\n\u001b[32m    336\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnreadable variable \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, because \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    337\u001b[39m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    338\u001b[39m     res = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmat_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_position\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m mdict[name] = res\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hdr.is_global:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "EPOCHS = 100  # Number of epochs for training\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "# Create a directory to save snapshots if it doesn't exist\n",
    "os.makedirs(\"snapshots\", exist_ok=True)\n",
    "# Number of splits for k-fold cross-validation\n",
    "k_folds = 5\n",
    "batch_size = 32\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "indices = list(range(len(train_data)))\n",
    "\n",
    "# Convert dataset to a tensor for splitting\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(train_data, train_idx)\n",
    "    val_subset = Subset(train_data, val_idx)\n",
    "    \n",
    "    # Create dataloaders for these subsets\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            if inputs.shape[0] != 32:\n",
    "                continue\n",
    "            inputs = inputs[:, :, :, :3].flatten(2)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.squeeze(1)\n",
    "\n",
    "\n",
    "            loss_value = loss(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Fold [{fold + 1}/{k_folds}], Epoch [{epoch + 1}/{EPOCHS}], \"\n",
    "                      f\"Step [{i + 1}/{len(train_loader)}], Loss: {loss_value.item():.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        f1_metric = MulticlassF1Score(num_classes=9, average='micro').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                if inputs.shape[0] != 32:\n",
    "                    continue\n",
    "                inputs = inputs.to(device)\n",
    "                inputs = inputs[:, :, :, :3].flatten(2)\n",
    "\n",
    "                targets = targets.to(device)  # shape: [batch_size, num_labels], values ∈ {0, 1}\n",
    "                targets = targets.squeeze(1)\n",
    "\n",
    "                print(f\"TARGETS {targets.shape}, INPUTS{inputs.shape}\")\n",
    "\n",
    "                logits = model(inputs)        # shape: [batch_size, num_labels]\n",
    "                preds = torch.sigmoid(logits) > 0.5  # threshold predictions → bool\n",
    "\n",
    "                f1_metric.update(preds.int(), targets.int())\n",
    "                \n",
    "        f1_score = f1_metric.compute()\n",
    "        print(f\"F1-score (micro): {f1_score.item():.4f}\")\n",
    "        f1_metric.reset()\n",
    "        # Save a snapshot of the model at each epoch\n",
    "        torch.save(model.state_dict(), f\"snapshots/model_fold{fold + 1}_epoch{epoch + 1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "eval_loss = 0\n",
    "\n",
    "f1_metric = MulticlassF1Score(num_classes=9, average='micro').to(device)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        if inputs.shape[0] != 32:\n",
    "            continue\n",
    "            \n",
    "        inputs = inputs[:, :, :, :3].flatten(2)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        targets.squeeze(1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update the metric\n",
    "        f1_metric.update(preds, targets)\n",
    "\n",
    "# Compute final F1\n",
    "f1_score = f1_metric.compute()\n",
    "print(f\"F1-score (micro): {f1_score.item():.4f}\")\n",
    "\n",
    "# Reset for next epoch\n",
    "f1_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
