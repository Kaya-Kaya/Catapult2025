{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pose_dataset import PoseData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 33 * 3\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2 # number of RNNs to stack\n",
    "NUM_CLASSES = 9 # number of categories\n",
    "\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_DIM = 1\n",
    "BATCH_DIM = 0\n",
    "COORD_DIM = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseScoringModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(PoseScoringModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        h0 = torch.zeros(self.num_layers, X.size(BATCH_DIM), self.hidden_size).to(device)\n",
    "        print(X.shape)\n",
    "        out, _ = self.gru(X, h0)\n",
    "        # out: batch x time x hidden\n",
    "        out = out[:, -1, :]\n",
    "        # out: batch x hidden\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoseScoringModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved pair (../data/data_114.mat, ../data/metric_114.mat) to ../data/train\n",
      "Moved pair (../data/data_115.mat, ../data/metric_115.mat) to ../data/train\n",
      "Moved pair (../data/data_116.mat, ../data/metric_116.mat) to ../data/train\n",
      "Moved pair (../data/data_117.mat, ../data/metric_117.mat) to ../data/test\n",
      "Moved pair (../data/data_118.mat, ../data/metric_118.mat) to ../data/train\n",
      "Moved pair (../data/data_119.mat, ../data/metric_119.mat) to ../data/test\n",
      "Moved pair (../data/data_120.mat, ../data/metric_120.mat) to ../data/train\n",
      "Moved pair (../data/data_121.mat, ../data/metric_121.mat) to ../data/train\n",
      "Moved pair (../data/data_122.mat, ../data/metric_122.mat) to ../data/train\n",
      "Moved pair (../data/data_123.mat, ../data/metric_123.mat) to ../data/train\n",
      "Moved pair (../data/data_124.mat, ../data/metric_124.mat) to ../data/train\n",
      "Moved pair (../data/data_125.mat, ../data/metric_125.mat) to ../data/train\n",
      "Moved pair (../data/data_126.mat, ../data/metric_126.mat) to ../data/train\n",
      "Moved pair (../data/data_127.mat, ../data/metric_127.mat) to ../data/train\n",
      "Moved pair (../data/data_128.mat, ../data/metric_128.mat) to ../data/train\n",
      "Moved pair (../data/data_129.mat, ../data/metric_129.mat) to ../data/train\n",
      "Moved pair (../data/data_130.mat, ../data/metric_130.mat) to ../data/test\n",
      "Moved pair (../data/data_131.mat, ../data/metric_131.mat) to ../data/train\n",
      "Moved pair (../data/data_132.mat, ../data/metric_132.mat) to ../data/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility (optional)\n",
    "# random.seed(42)\n",
    "\n",
    "# Set the training ratio (90% training, 10% testing)\n",
    "train_ratio = 0.9\n",
    "\n",
    "# Define target directories\n",
    "train_dir = \"../data/train\"\n",
    "test_dir = \"../data/test\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Get a sorted list of all data files\n",
    "data_files = sorted(glob.glob(\"../data/data_*.mat\"))\n",
    "data_files = data_files[:19]\n",
    "\n",
    "for data_file in data_files:\n",
    "    # Get the base filename without extension, e.g., \"data_000\"\n",
    "    base_name = os.path.splitext(os.path.basename(data_file))[0]\n",
    "    parts = base_name.split('_')\n",
    "    if len(parts) != 2:\n",
    "        print(f\"Skipping invalid file name: {data_file}\")\n",
    "        continue\n",
    "    number = parts[1]  # e.g., \"000\"\n",
    "    \n",
    "    # Construct the corresponding metric filename\n",
    "    metric_file = f\"../data/metric_{number}.mat\"\n",
    "    \n",
    "    # Check if the corresponding metric file exists\n",
    "    if not os.path.exists(metric_file):\n",
    "        print(f\"Warning: {metric_file} not found for {data_file}\")\n",
    "        continue\n",
    "\n",
    "    # Choose destination based on random split\n",
    "    destination = train_dir if random.random() < train_ratio else test_dir\n",
    "\n",
    "    # Move both files\n",
    "    shutil.move(data_file, os.path.join(destination, os.path.basename(data_file)))\n",
    "    shutil.move(metric_file, os.path.join(destination, os.path.basename(metric_file)))\n",
    "    \n",
    "    print(f\"Moved pair ({data_file}, {metric_file}) to {destination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PoseData(\"../data/train\")\n",
    "test_data = PoseData(\"../data/test\")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "# train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [1/10], Step [1/4], Loss: 9.7518\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [2/10], Step [1/4], Loss: 9.4773\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [3/10], Step [1/4], Loss: 9.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarik/miniconda3/envs/catapult/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MulticlassF1Score was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [4/10], Step [1/4], Loss: 9.2689\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [5/10], Step [1/4], Loss: 10.6421\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [6/10], Step [1/4], Loss: 11.0555\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [7/10], Step [1/4], Loss: 10.3014\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [8/10], Step [1/4], Loss: 13.5884\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [9/10], Step [1/4], Loss: 10.0943\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [1/5], Epoch [10/10], Step [1/4], Loss: 11.3980\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "Fold 2/5\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [1/10], Step [1/4], Loss: 10.8490\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [2/10], Step [1/4], Loss: 11.1913\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [3/10], Step [1/4], Loss: 10.0248\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [4/10], Step [1/4], Loss: 10.5734\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [5/10], Step [1/4], Loss: 9.4762\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [6/10], Step [1/4], Loss: 10.5747\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [7/10], Step [1/4], Loss: 10.5063\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [8/10], Step [1/4], Loss: 8.6502\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [9/10], Step [1/4], Loss: 10.7842\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [2/5], Epoch [10/10], Step [1/4], Loss: 10.7780\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "Fold 3/5\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [1/10], Step [1/4], Loss: 9.9565\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [2/10], Step [1/4], Loss: 8.1640\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [3/10], Step [1/4], Loss: 11.3243\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [4/10], Step [1/4], Loss: 11.1194\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [5/10], Step [1/4], Loss: 8.7912\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [6/10], Step [1/4], Loss: 10.8194\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [7/10], Step [1/4], Loss: 10.1612\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [8/10], Step [1/4], Loss: 9.2010\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [9/10], Step [1/4], Loss: 10.2309\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [3/5], Epoch [10/10], Step [1/4], Loss: 10.5740\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "Fold 4/5\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [1/10], Step [1/4], Loss: 9.2008\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [2/10], Step [1/4], Loss: 12.0161\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [3/10], Step [1/4], Loss: 10.5054\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [4/10], Step [1/4], Loss: 12.2222\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [5/10], Step [1/4], Loss: 10.9174\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [6/10], Step [1/4], Loss: 10.4368\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [7/10], Step [1/4], Loss: 11.8787\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [8/10], Step [1/4], Loss: 9.4757\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [9/10], Step [1/4], Loss: 10.9175\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [4/5], Epoch [10/10], Step [1/4], Loss: 11.4668\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "Fold 5/5\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [1/10], Step [1/4], Loss: 10.2995\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [2/10], Step [1/4], Loss: 7.5529\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [3/10], Step [1/4], Loss: 11.7413\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [4/10], Step [1/4], Loss: 11.0548\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [5/10], Step [1/4], Loss: 10.8488\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [6/10], Step [1/4], Loss: 8.7203\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [7/10], Step [1/4], Loss: 10.7115\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [8/10], Step [1/4], Loss: 11.1235\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [9/10], Step [1/4], Loss: 13.5266\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n",
      "torch.Size([32, 36, 99])\n",
      "Fold [5/5], Epoch [10/10], Step [1/4], Loss: 9.3383\n",
      "torch.Size([32, 36, 99])\n",
      "torch.Size([32, 36, 99])\n",
      "F1-score (micro): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "\n",
    "EPOCHS = 10  # Number of epochs for training\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "# Create a directory to save snapshots if it doesn't exist\n",
    "os.makedirs(\"snapshots\", exist_ok=True)\n",
    "# Number of splits for k-fold cross-validation\n",
    "k_folds = 5\n",
    "batch_size = 32\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "indices = list(range(len(train_data)))\n",
    "\n",
    "# Convert dataset to a tensor for splitting\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(indices)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(train_data, train_idx)\n",
    "    val_subset = Subset(train_data, val_idx)\n",
    "    \n",
    "    # Create dataloaders for these subsets\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "            if inputs.shape[0] != 32:\n",
    "                continue\n",
    "            inputs = inputs[:, :, :, :3].flatten(2)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            targets = targets.squeeze(1)\n",
    "            loss_value = loss(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Fold [{fold + 1}/{k_folds}], Epoch [{epoch + 1}/{EPOCHS}], \"\n",
    "                      f\"Step [{i + 1}/{len(train_dataloader)}], Loss: {loss_value.item():.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        f1_metric = MulticlassF1Score(num_classes=3, average='micro').to(device)\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                if inputs.shape[0] != 32:\n",
    "                    continue\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                inputs = inputs[:, :, :, :3].flatten(2)\n",
    "\n",
    "                logits = model(inputs)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "                # Update the metric\n",
    "                f1_metric.update(preds, targets)\n",
    "                \n",
    "        f1_score = f1_metric.compute()\n",
    "        print(f\"F1-score (micro): {f1_score.item():.4f}\")\n",
    "        f1_metric.reset()\n",
    "        # Save a snapshot of the model at each epoch\n",
    "        torch.save(model.state_dict(), f\"snapshots/model_fold{fold + 1}_epoch{epoch + 1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 36, 33, 4])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GRU: Expected input to be 2D or 3D, got 4D instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[32m     10\u001b[39m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     preds = torch.argmax(logits, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Update the metric\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mPoseScoringModel.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     11\u001b[39m h0 = torch.zeros(\u001b[38;5;28mself\u001b[39m.num_layers, X.size(BATCH_DIM), \u001b[38;5;28mself\u001b[39m.hidden_size).to(device)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(X.shape)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# out: batch x time x hidden\u001b[39;00m\n\u001b[32m     15\u001b[39m out = out[:, -\u001b[32m1\u001b[39m, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/catapult/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1356\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1354\u001b[39m batch_sizes = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.dim() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1357\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGRU: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mD instead\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1358\u001b[39m     )\n\u001b[32m   1359\u001b[39m is_batched = \u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m3\u001b[39m\n\u001b[32m   1360\u001b[39m batch_dim = \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: GRU: Expected input to be 2D or 3D, got 4D instead"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "eval_loss = 0\n",
    "\n",
    "f1_metric = MulticlassF1Score(num_classes=3, average='micro').to(device)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update the metric\n",
    "        f1_metric.update(preds, targets)\n",
    "\n",
    "# Compute final F1\n",
    "f1_score = f1_metric.compute()\n",
    "print(f\"F1-score (micro): {f1_score.item():.4f}\")\n",
    "\n",
    "# Reset for next epoch\n",
    "f1_metric.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
